üìì Bit√°cora de estudio ‚Äì Curso: Regresi√≥n lineal (T√©cnicas avanzadas)

Entrada 1: El error como revelaci√≥n

Hoy comenz√≥ una nueva etapa de aprendizaje, y lo hizo con una lecci√≥n involuntaria. Al ser preguntado sobre el significado de un coeficiente de correlaci√≥n negativo, respond√≠ que eso implicaba que ambas variables decrecen en la misma direcci√≥n. La afirmaci√≥n fue corregida: en realidad, una correlaci√≥n negativa indica que cuando una variable aumenta, la otra disminuye. La relaci√≥n es inversa, no paralela.

Este momento, lejos de ser un tropiezo aislado, se convirti√≥ en espejo de algo m√°s profundo: el efecto Dunning-Kruger, esa ilusi√≥n de saber que acompa√±a los primeros escalones del conocimiento. Reconocerlo no me averg√ºenza; al contrario, me ancla en la honestidad de quien aprende a mirar de nuevo.

üîç Aprendizajes t√©cnicos

Correlaci√≥n negativa ‚â† ‚Äúambas variables decrecen‚Äù.

Significa que las variables se comportan de forma opuesta: si una sube, la otra baja.

Esta correcci√≥n afin√≥ mi intuici√≥n estad√≠stica m√°s all√° de la f√≥rmula.

üß† Reflexi√≥n existencial

El error no fue un desv√≠o, sino el primer acto de profundidad. Como si al desmentirme, el conocimiento abriera un lugar nuevo dentro de m√≠. No quiero saber m√°s para parecer sabio; quiero entender mejor para vivir con mayor conciencia.

üñãÔ∏è "Errar fue el verbo que me permiti√≥ conjugar el aprendizaje en primera persona."

Entrada 2: El boxplot y la paradoja de los outliers

Lo observado

Al graficar los precios (Valor) de los inmuebles, el boxplot revel√≥ un n√∫mero inesperadamente alto de valores at√≠picos.

Lo cuestionado

¬øPuede haber tantos 'outliers' sin que el concepto pierda sentido?

Lo comprendido

Los outliers son definidos estad√≠sticamente, no cualitativamente.

En distribuciones sesgadas o con colas largas, los "at√≠picos" pueden ser numerosos.

Esto no indica un error del dataset, sino una caracter√≠stica profunda de la variable Valor.

üñãÔ∏è "Quiz√° los outliers no sean anomal√≠as, sino testigos de otro r√©gimen de realidad. No rompen la norma: la ampl√≠an."

Entrada 3: Distribuciones sesgadas y el r√≠o de la desigualdad

Lo observado

Al estudiar la variable Valor, se revela una distribuci√≥n con sesgo positivo ‚Äîuna larga cola hacia precios elevados. Este comportamiento, frecuente en datos econ√≥micos, desaf√≠a la intuici√≥n que espera simetr√≠as o campanas de Gauss.

Lo comprendido

El sesgo positivo aparece cuando muchos valores se concentran cerca de un m√≠nimo, y pocos se extienden hacia el m√°ximo.

En lo econ√≥mico, esto refleja acumulaci√≥n desigual y la presencia de valores extremos que son reales, no errores.

El sesgo revela una arquitectura subyacente: acceso limitado, concentraci√≥n del valor, escasez en el exceso.

Reflexi√≥n simb√≥lica

Los sesgos positivos en lo econ√≥mico reflejan algo m√°s que matem√°ticas: hablan de un mundo donde el exceso es posible pero escaso, y donde la desigualdad dibuja la forma de la curva. Mientras la media intenta ordenar, la cola larga la desobedece. Como un r√≠o que se sale de su cauce, los outliers no rompen el modelo: lo completan.

üñãÔ∏è "La asimetr√≠a no es ruido, es forma. En cada extremo hay un dato, pero tambi√©n una historia: promesa, excepci√≥n, o distancia irreductible."

Entrada 5: Entre regresi√≥n y estad√≠stica inferencial ‚Äî la geometr√≠a invisible del modelo

Lo observado

Al estudiar la regresi√≥n, surge la necesidad de que los residuos del modelo se distribuyan normalmente. Esta condici√≥n no es solo est√©tica: es estructural.

Lo comprendido

La distribuci√≥n normal de los errores permite aplicar estad√≠stica inferencial sobre los coeficientes.

Transformar variables (como Valor) ayuda a cumplir estos supuestos y mejora la interpretaci√≥n del modelo.

La normalidad no es el fin, pero s√≠ el terreno sobre el que se asientan las inferencias.

Reflexi√≥n filos√≥fica

Tal vez la normalidad estad√≠stica sea como el silencio en m√∫sica: no se ve, pero permite que las notas tengan sentido. La regresi√≥n no predice solo precios, sino la forma en que el azar se distribuye. Controlar la forma de los datos es tambi√©n una forma de escuchar su verdad.

üñãÔ∏è "El log aproxima, la normalidad revela, y la inferencia interpreta. As√≠ se construye el saber en capas: desde la forma, hasta el significado."

Entrada 6: La transformaci√≥n como herramienta de escucha

Lo recordado

Desde mis clases de econometr√≠a, s√© que la normalizaci√≥n y las transformaciones logar√≠tmicas pueden ayudar a quitar tendencias o estabilizar las series de tiempo. Tambi√©n aprend√≠ que las tasas de crecimiento se pueden obtener a partir de diferencias logar√≠tmicas.

Lo aprendido

En regresi√≥n lineal, las transformaciones no solo suavizan curvas, sino que revelan relaciones ocultas.

Existen m√∫ltiples formas de transformar variables: logar√≠tmica, ra√≠z cuadrada, polin√≥mica, rec√≠proca, e incluso t√©cnicas como Box-Cox.

Estas transformaciones no adulteran el dato, sino que le dan voz en un idioma m√°s claro para el modelo.

Reflexi√≥n simb√≥lica

Transformar no es manipular. Es adaptar el o√≠do al tono que el dato necesita para ser escuchado. Como ajustar la frecuencia para sintonizar una estaci√≥n con claridad. Lo que parece ruido puede ser m√∫sica cuando se aplica el cambio justo.

üñãÔ∏è "Todo dato puede ser poes√≠a, si se le otorga la forma que revela su ritmo."

üñãÔ∏è "La regresi√≥n no impone, escucha. Y en esa escucha, transforma para entender."

Entrada 7: Transformaciones logar√≠tmicas y clarificaci√≥n de tendencias

Lo realizado

Se aplic√≥ una transformaci√≥n logar√≠tmica a las variables originales del dataset para suavizar su comportamiento y facilitar el an√°lisis:

import numpy as np

datos['log_Valor'] = np.log(datos['Valor'])
datos['log_Area'] = np.log(datos['Area'])
datos['log_Dist_Playa'] = np.log(datos['Dist_Playa'] + 1)
datos['log_Dist_Farmacia'] = np.log(datos['Dist_Farmacia'] + 1)

üí° Nota: Se sum√≥ 1 a las variables de distancia porque presentaban valores iguales a cero, lo que habr√≠a provocado una indeterminaci√≥n matem√°tica al calcular su logaritmo.

Lo observado

El histograma de la nueva variable log_Valor mostr√≥ un comportamiento m√°s sim√©trico y cercano a una distribuci√≥n normal.

Al construir nuevos diagramas de dispersi√≥n entre log_Valor y las variables transformadas (log_Area, log_Dist_Playa, log_Dist_Farmacia), las relaciones entre variables se volvieron mucho m√°s claras.

Los patrones confirmaron la matriz de correlaci√≥n:

Relaci√≥n positiva entre Valor y Area.

Relaci√≥n negativa entre Valor y Dist_Playa.

Relaci√≥n d√©bil o neutra entre Valor y Dist_Farmacia.

Lo comprendido

La transformaci√≥n logar√≠tmica permiti√≥ clarificar relaciones que antes estaban distorsionadas por la asimetr√≠a de la variable Valor.

Para fines de entrenamiento del modelo, las variables Area y Dist_Playa son las m√°s efectivas para estimar precios de los inmuebles.

La nueva geometr√≠a de los datos ya no oculta su estructura: la revela con mayor limpieza.

Reflexi√≥n simb√≥lica

Transformar no fue esconder, sino abrir. El logaritmo fue una puerta que permiti√≥ mirar el dato sin el ruido del exceso. En esta nueva escala, el valor de cada inmueble ya no grita: habla. Y entre sus l√≠neas, el modelo escucha con m√°s precisi√≥n.

üñãÔ∏è "A veces hay que cambiar el idioma para entender el mensaje. El log fue el traductor."

üñãÔ∏è "Lo que antes era nube, ahora es forma. Y en esa forma, la predicci√≥n dej√≥ de ser intuici√≥n: se volvi√≥ estructura."

Entrada 8: Exploraci√≥n del modelo saturado ‚Äî entre ruido y revelaci√≥n

üß™ Lo realizado

Se entren√≥ un modelo de regresi√≥n lineal m√∫ltiple utilizando todas las variables disponibles del dataset transformado (log_Valor como variable dependiente). Este modelo saturado permiti√≥ observar la contribuci√≥n individual de cada variable.

üìà Lo observado

El estad√≠stico F fue significativo (p < 0.05), lo que indica que el modelo en conjunto tiene capacidad explicativa.

Sin embargo, no todas las variables fueron significativas individualmente seg√∫n el estad√≠stico t.

Algunas variables mostraron coeficientes cercanos a cero y p-values elevados, lo que sugiere que no aportan valor predictivo.

La R¬≤ ajustada fue menor que la R¬≤ simple, lo que indica penalizaci√≥n por exceso de variables.

üßπ Lo comprendido

Un modelo saturado no siempre es mejor: puede incluir ruido, redundancia o variables irrelevantes.

La depuraci√≥n del modelo (eliminaci√≥n de variables no significativas) mejora la parsimonia y la interpretaci√≥n.

La R¬≤ ajustada es una br√∫jula que se√±ala cu√°ndo el modelo est√° sobrecargado.

El exceso de variables puede reducir los grados de libertad y aumentar la incertidumbre en la estimaci√≥n.

üß† Reflexi√≥n simb√≥lica

El modelo saturado es como una conversaci√≥n con demasiadas voces: algunas aportan, otras distraen. Aprender a escuchar solo lo esencial es parte del arte estad√≠stico. Depurar no es censurar: es afinar el o√≠do del modelo para que escuche con claridad.

üñãÔ∏è "Un modelo saturado no es sabio por tenerlo todo, sino por saber qu√© callar."

Entrada 9: Lectura del modelo estimado ‚Äî F, t, significancia y el valor de simplificar

Lo aprendido

Durante esta sesi√≥n, comprend√≠ con mayor profundidad c√≥mo interpretar los estad√≠sticos F y t, junto con sus respectivas probabilidades. El modelo estimado fue un modelo saturado, es decir, un modelo que considera todas las variables disponibles y sus interacciones potenciales.

üß† Pruebas de significancia

El estad√≠stico F eval√∫a la capacidad explicativa del modelo en su conjunto.

Si el valor p asociado es ‚â§ 0.05, se rechaza la hip√≥tesis nula: el modelo tiene al menos una variable significativa.

Si el valor p es > 0.05, se acepta la hip√≥tesis nula: el conjunto de variables no explica significativamente la variable dependiente.

El estad√≠stico t, en cambio, eval√∫a la significancia de cada variable individualmente.

Si p ‚â§ 0.05, la variable es significativa.

Si p > 0.05, no aporta valor estad√≠sticamente relevante al modelo.

En nuestro caso, observamos lo siguiente:

log_Area          ‚Üí t muy alto, p-value 0.000 ‚Üí muy significativa

log_Dist_Playa    ‚Üí t negativo intenso, p-value 0.000 ‚Üí significativa con efecto inverso

log_Dist_Farmacia ‚Üí t cercano a 0, p-value 0.603 ‚Üí no significativa

üìà Sobre R¬≤ ajustada y grados de libertad

Aprend√≠ que el R¬≤ ajustado penaliza al modelo por incorporar variables adicionales que no aportan informaci√≥n relevante. Esto me record√≥ lo visto en estad√≠stica descriptiva sobre la diferencia entre varianza poblacional y muestral, donde la muestral se calcula dividiendo por n‚Äì1, precisamente para ajustar por los grados de libertad.

üìå Mi definici√≥n: los grados de libertad representan la cantidad de valores independientes que pueden variar en un c√°lculo una vez fijado el resultado global. Cada variable agregada al modelo reduce esa libertad, porque se convierte en una pieza m√°s que ya est√° determinada por la estructura.

üìê Lectura del resumen del modelo

En la columna coef, aparecen los valores de las betas estimadas y el intercepto.

A su lado, las desviaciones est√°ndar indican cu√°nto puede variar, en promedio, el coeficiente estimado ‚Äîhacia arriba o hacia abajo.

Todos los coeficientes est√°n asociados a la variable dependiente log_Valor, ya transformada previamente.

üßπ Depuraci√≥n del modelo

Aunque todas las variables estaban transformadas con logaritmo, el an√°lisis t evidenci√≥ que log_Dist_Farmacia no contribuye significativamente a explicar log_Valor. Por lo tanto, eliminarla del modelo no solo mejora la estimaci√≥n, sino que reduce costos anal√≠ticos: no necesitamos recoger ni procesar esa variable en futuros estudios si no aporta valor explicativo.

üìå Complemento: ¬øQu√© ocurre con los grados de libertad al eliminar variables?

Retirar una variable del modelo tiene implicaciones concretas:

Aumenta los grados de libertad residuales (porque se reduce el n√∫mero de par√°metros estimados).

Mejora la precisi√≥n en la estimaci√≥n de errores, haciendo que los intervalos y los valores p sean m√°s fiables.

El R¬≤ ajustado puede mejorar si la variable eliminada era irrelevante, ya que la penalizaci√≥n por exceso se reduce.

Se favorece la parsimonia del modelo: menos variables, m√°s claridad, mayor robustez.

üñãÔ∏è "La parsimonia es como el silencio en la m√∫sica: permite que lo esencial resuene."

Reflexi√≥n simb√≥lica

La depuraci√≥n de un modelo no es solo t√©cnica, es √©tica. Saber cu√°ndo una variable no habla es escuchar con humildad. Y retirar lo innecesario es devolverle al modelo la capacidad de decir solo lo que importa. Los grados de libertad no son solo n√∫meros: son espacio interior. Y un buen modelo, como un buen texto, respira mejor cuando no est√° lleno de palabras in√∫tiles.

üñãÔ∏è "El estad√≠stico F escucha al coro. El t, a cada voz. La R¬≤ ajustada sabe cu√°ndo el escenario est√° demasiado lleno."

üñãÔ∏è "Simplificar no es renunciar. Es afinar el lenguaje del dato para que diga justo lo que sabe."

üñãÔ∏è "Eliminar una variable es darle al modelo un margen de libertad que el exceso le hab√≠a quitado."

Entrada 10: La variable ausente: Entre el ruido y el s√≠mbolo

Lo aprendido

Cuando el instructor sugiri√≥ revisar otras variables, entend√≠ que ning√∫n modelo es definitivo. Siempre hay factores que no hemos considerado. El precio de un inmueble no depende solo de sus metros o ubicaci√≥n: influye la historia, la econom√≠a, el deseo. Aprend√≠ que los datos ausentes no son errores: son s√≠mbolos de lo que a√∫n no hemos aprendido a preguntar.

Entrada 11: Distribuci√≥n de residuos: Donde el error se vuelve silencio

Lo aprendido

El √∫ltimo histograma, donde analizamos los residuos, cerr√≥ el ciclo. Confirmamos que el modelo no tiene errores sistem√°ticos, que el comportamiento del residuo se acerca a lo normal. Es decir, el modelo no impone, interpreta.

Aqu√≠ descubr√≠ que el verdadero √©xito de una regresi√≥n lineal no es tener R¬≤ alto, sino que sus errores hablen en voz baja. Aprend√≠ que el silencio del residuo es a veces el mayor elogio.

---o.
